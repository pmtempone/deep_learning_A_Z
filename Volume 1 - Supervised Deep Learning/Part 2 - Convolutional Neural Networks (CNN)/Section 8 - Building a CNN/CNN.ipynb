{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial correspond to the section 10 (building a CNN) of **DEEP LEARNING A-Z** from https://www.udemy.com/deeplearning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense #add fully connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cnn_process.png](cnn_process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step_1.png](step_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![feature_map.png](feature_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![input_images.png](input_images.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu activation function\n",
    "\n",
    "To get not linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![relu.png](relu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step2_maxpool.png](step2_maxpool.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step3_flattening.png](step3_flattening.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Full connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![step4_fullconn.png](step4_fullconn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_function.png](loss_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Fitting the CNN to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about Keras library can be found in https://keras.io. We use Image Preprocessing.\n",
    "\n",
    "Image augmentation trick can only reduce overfitting.\n",
    "\n",
    "In summary image augmentation is a technique that allows us to enrich our data sets are that without adding more images and therefore that allows us to get good performance results with little or no overfitting even with a small amount of images.\n",
    "\n",
    "So now let's apply this image augmentation on our images and to do this we are going to use this shortcut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, #pixel values will be between 0 and 1\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 134s 535ms/step - loss: 0.2794 - acc: 0.8752 - val_loss: 0.4135 - val_acc: 0.8270\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 125s 500ms/step - loss: 0.2727 - acc: 0.8812 - val_loss: 0.4109 - val_acc: 0.8360\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 126s 505ms/step - loss: 0.2633 - acc: 0.8887 - val_loss: 0.4282 - val_acc: 0.8320\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 126s 502ms/step - loss: 0.2560 - acc: 0.8884 - val_loss: 0.4596 - val_acc: 0.8235\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 125s 501ms/step - loss: 0.2403 - acc: 0.8985 - val_loss: 0.4923 - val_acc: 0.8200\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 127s 506ms/step - loss: 0.2302 - acc: 0.9034 - val_loss: 0.4534 - val_acc: 0.8290\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 127s 510ms/step - loss: 0.2355 - acc: 0.8995 - val_loss: 0.4255 - val_acc: 0.8415\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 127s 509ms/step - loss: 0.2201 - acc: 0.9042 - val_loss: 0.4674 - val_acc: 0.8330\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 130s 521ms/step - loss: 0.2098 - acc: 0.9149 - val_loss: 0.5019 - val_acc: 0.8270\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 130s 519ms/step - loss: 0.2020 - acc: 0.9155 - val_loss: 0.4862 - val_acc: 0.8195\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 128s 512ms/step - loss: 0.1974 - acc: 0.9191 - val_loss: 0.5165 - val_acc: 0.8265\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 0.1879 - acc: 0.9236 - val_loss: 0.5590 - val_acc: 0.8230\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 127s 507ms/step - loss: 0.1771 - acc: 0.9289 - val_loss: 0.4706 - val_acc: 0.8265\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 0.1630 - acc: 0.9360 - val_loss: 0.5330 - val_acc: 0.8395\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 121s 483ms/step - loss: 0.1666 - acc: 0.9345 - val_loss: 0.5026 - val_acc: 0.8355\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 120s 482ms/step - loss: 0.1716 - acc: 0.9314 - val_loss: 0.5218 - val_acc: 0.8300\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 121s 484ms/step - loss: 0.1540 - acc: 0.9404 - val_loss: 0.5391 - val_acc: 0.8350\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 0.1534 - acc: 0.9374 - val_loss: 0.5929 - val_acc: 0.8155\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 120s 479ms/step - loss: 0.1467 - acc: 0.9411 - val_loss: 0.6277 - val_acc: 0.8140\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 120s 482ms/step - loss: 0.1373 - acc: 0.9439 - val_loss: 0.5635 - val_acc: 0.8320\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 120s 481ms/step - loss: 0.1436 - acc: 0.9439 - val_loss: 0.5871 - val_acc: 0.8185\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 120s 480ms/step - loss: 0.1260 - acc: 0.9490 - val_loss: 0.6039 - val_acc: 0.8180\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 121s 482ms/step - loss: 0.1339 - acc: 0.9464 - val_loss: 0.5970 - val_acc: 0.8250\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 0.1231 - acc: 0.9534 - val_loss: 0.6514 - val_acc: 0.8330\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 0.1309 - acc: 0.9478 - val_loss: 0.5998 - val_acc: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b032d68>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000/32,#observation over the batch size\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the CNN can predict that Luna is a Dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![luna2.jpg](/dataset/single_prediction/luna2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/luna2.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
